# Exercise-13

Welcome to exercise-13. Here we will try to do some basics training about logging and debugging of our applications and components in Kubernetes environment.

## Kubernetes logs

Everything a containerized application write to **stdout** and **stderr** is handled and redirected somewhere by a container engine. For example, the Docker engine redirects those two streams to a logging driver (which is by default json-file).

To see the logs you need to run the below commands:

```bash
kubectl logs <name_of_the_pod> 

## for logs streaming
kubectl logs <name_of_the_pod> -f

## for selected container in multi container pod
kubectl logs <name_of_the_pod> -c <name_of_the_container_in_pod> 
```

Another option is to see the logs from the Kubernetes Dashboard. Go to kubernetes dashboard, select the pod then click on the logs icon to see the logs. From there you can easily switch between containers.

**kubetail** is another good tool to read the logs from multi containers to aggregate the view:

[https://github.com/johanhaleby/kubetail](https://github.com/johanhaleby/kubetail)

Installation and example usage:

```bash
sudo curl https://raw.githubusercontent.com/johanhaleby/kubetail/master/kubetail >> /usr/local/bin/kubetail
sudo chmod +x /usr/local/bin/kubetail

example of usage

kubetail <pod_prefix> -f
```

## EFK

EFK stands from Elasticsearch, Fluentd and Kibana.

To install the components, follow the below steps.

1. Create the namespace for logging components

```bash
kubectl create namespace logging
```

2. **Elastisearch**

```bash
kubectl apply -f elastic.yaml -n logging

# verify

kubectl get pods -n logging
kubectl get svc -n logging
kubectl get ingress -n logging

# take a note of ingress address and add correspond entry in /etc/hosts to point to our ElasticSearch instance
sudo vim /etc/hosts
# example: 192.168.99.104 es.minikube.local

# Query the ElasticSearch to make sure the service is running
curl es.minikube.local
```
3. **Fluentd**

```bash
# Apply the necessary RBAC permissions
kubectl apply -f fluentd-rbac.yaml

# Create the DaemonSet
kubectl apply -f fluetnd-daemonset.yaml

# Verify
kubectl get pod -n kube-system

# Take a note of fluentd pod and use here 
kubectl logs <fluentd_pod> -n kube-system

# Expect the output like:
# Connection opened to Elasticsearch cluster =>
#  {:host=>"elasticsearch.logging", :port=>9200, :scheme=>"http"}
```

4. **Kibana**

```bash
kubectl apply -f kibana.yaml -n logging

# verify

kubectl get pods -n logging
kubectl get svc -n logging
kubectl get ingress -n logging

# take a note of ingress address and add correspond entry in /etc/hosts to point to our ElasticSearch instance
sudo vim /etc/hosts
# example: 192.168.99.104 kibana.minikube.local
http://kibana.minikube.local
```

5. Sample application

```
kubectl create -f app-example.yaml

kubectl get pod

# take a note of the pod and use now

kubectl logs -f <pod>

# It will print the timestamps every second
```

6. Configure Kibana
  - Click **Management** and then select **Index Patterns** under **Kibana**
  - Click the **Create index pattern**. Select the new Logstash index that is generated by the Fluentd DaemonSet ( **logstash + star**). Click **Next step**
  - Set the **Time Filter field name** to **@timestamp**. Then, click **Create index pattern**
  - Click **Discover** to view your application logs

